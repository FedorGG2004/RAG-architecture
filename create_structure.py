import os
import sys
from pathlib import Path

def create_project_structure():
    # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è Windows
    base_dir = Path(r"C:\Users\Fedor\Desktop\Diplom")
    
    print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è Windows 10...")
    
    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è
    directories = [
        ".vscode",
        "src",
        "data/chroma_db",
        "data/test_documents", 
        "data/knowledge_base",
        "tests",
        "docs"
    ]
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    for directory in directories:
        dir_path = base_dir / directory
        dir_path.mkdir(parents=True, exist_ok=True)
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞: {dir_path}")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è Windows)
    files_content = {
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è VS Code
        ".vscode/settings.json": '''{
    "python.defaultInterpreterPath": "venv\\\\Scripts\\\\python.exe",
    "python.analysis.extraPaths": ["./src"],
    "files.exclude": {
        "**/__pycache__": true,
        "**/*.pyc": true,
        "**/.pytest_cache": true
    },
    "editor.formatOnSave": true,
    "python.formatting.provider": "black"
}''',
        
        ".vscode/launch.json": '''{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: RAG System",
            "type": "python",
            "request": "launch",
            "program": "src/main.py",
            "console": "integratedTerminal",
            "justMyCode": true
        }
    ]
}''',
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã
        "requirements.txt": '''ollama
chromadb
sentence-transformers
requests
numpy
pydantic
python-dotenv''',
        
        "src/__init__.py": "# RAG System Package",
        
        "src/config.py": '''import os
from pathlib import Path

# –ë–∞–∑–æ–≤—ã–µ –ø—É—Ç–∏
BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / "data"
VECTOR_DB_DIR = DATA_DIR / "chroma_db"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
MODEL_NAME = "tinyllama:1.1b"
OLLAMA_HOST = "http://localhost:11434"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
CHROMA_COLLECTION_NAME = "diplom_rag_memory"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞
TOP_K_RESULTS = 3

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
VECTOR_DB_DIR.mkdir(parents=True, exist_ok=True)
(DATA_DIR / "test_documents").mkdir(parents=True, exist_ok=True)
(DATA_DIR / "knowledge_base").mkdir(parents=True, exist_ok=True)''',
        
        "src/vector_db.py": '''import chromadb
from sentence_transformers import SentenceTransformer
import logging
from config import *

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VectorStore:
    def __init__(self):
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        self.client = chromadb.PersistentClient(path=str(VECTOR_DB_DIR))
        self.collection = self.client.get_or_create_collection(CHROMA_COLLECTION_NAME)
        self.embedder = SentenceTransformer(EMBEDDING_MODEL)
        logger.info("–í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î –≥–æ—Ç–æ–≤–∞!")
    
    def add_documents(self, documents, metadata_list=None):
        try:
            if metadata_list is None:
                metadata_list = [{}] * len(documents)
            
            embeddings = self.embedder.encode(documents).tolist()
            
            self.collection.add(
                embeddings=embeddings,
                documents=documents,
                metadatas=metadata_list,
                ids=[f"doc_{i}" for i in range(len(documents))]
            )
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            return False
    
    def search_similar(self, query, top_k=TOP_K_RESULTS):
        try:
            query_embedding = self.embedder.encode([query]).tolist()
            
            results = self.collection.query(
                query_embeddings=query_embedding,
                n_results=top_k
            )
            
            documents = results["documents"][0] if results["documents"] else []
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(documents)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return documents
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []''',
        
        "src/rag_system.py": '''import ollama
from vector_db import VectorStore
import logging
from datetime import datetime
from config import *

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RAGSystem:
    def __init__(self, model_name=MODEL_NAME):
        self.model_name = model_name
        self.vector_db = VectorStore()
        self.dialog_history = []
        logger.info(f"RAG —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å –º–æ–¥–µ–ª—å—é: {model_name}")
    
    def build_prompt(self, query, context_documents, history):
        context = " ".join(context_documents) if context_documents else "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."
        recent_history = " ".join(history[-4:]) if history else "–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –ø—É—Å—Ç–∞."
        
        prompt = f"""–ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}

–ò—Å—Ç–æ—Ä–∏—è: {recent_history}

–í–æ–ø—Ä–æ—Å: {query}

–û—Ç–≤–µ—Ç:"""
        return prompt
    
    def process_query(self, user_query):
        logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å: {user_query}")
        relevant_docs = self.vector_db.search_similar(user_query)
        prompt = self.build_prompt(user_query, relevant_docs, self.dialog_history)
        
        try:
            logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
            response = ollama.generate(
                model=self.model_name,
                prompt=prompt
            )
            answer = response['response'].strip()
            logger.info("–û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞: {e}"
            logger.error(error_msg)
            answer = error_msg
        
        self.dialog_history.extend([f"User: {user_query}", f"Assistant: {answer}"])
        return answer

    def add_initial_knowledge(self):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π –≤ —Å–∏—Å—Ç–µ–º—É"""
        initial_knowledge = [
            "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - —ç—Ç–æ —Ä–∞–∑–¥–µ–ª –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.",
            "Python –ø–æ–ø—É–ª—è—Ä–Ω—ã–π —è–∑—ã–∫ –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è.",
            "RAG –æ–∑–Ω–∞—á–∞–µ—Ç Retrieval-Augmented Generation.",
            "–û–ª–ªa–º–∞ - –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π."
        ]
        self.vector_db.add_documents(
            initial_knowledge,
            [{"source": "base_knowledge"}] * len(initial_knowledge)
        )''',
        
        "src/main.py": '''from rag_system import RAGSystem

def main():
    print("=" * 50)
    print("RAG System for Diplom Project")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
    rag = RAGSystem()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
    rag.add_initial_knowledge()
    
    print("–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞! –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'quit' –¥–ª—è –≤—ã—Ö–æ–¥–∞)")
    
    while True:
        user_input = input("\\n–í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'q']:
            print("–î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break
            
        if user_input:
            response = rag.process_query(user_input)
            print(f"–û—Ç–≤–µ—Ç: {response}")

if __name__ == "__main__":
    main()''',
        
        "README.md": '''# RAG System for Diplom

–ü—Ä–æ—Å—Ç–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞.

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞
1. pip install -r requirements.txt
2. ollama serve
3. python src/main.py'''
    }
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã
    for file_path, content in files_content.items():
        full_path = base_dir / file_path
        try:
            with open(full_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {full_path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è {full_path}: {e}")
    
    print("\\n" + "="*50)
    print("üéâ –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê –°–û–ó–î–ê–ù–ê!")
    print("="*50)
    print("üìã –î–∞–ª—å–Ω–µ–π—à–∏–µ —à–∞–≥–∏:")
    print("1. –û—Ç–∫—Ä–æ–π—Ç–µ –ø–∞–ø–∫—É 'Diplom' –≤ VS Code")
    print("2. –í —Ç–µ—Ä–º–∏–Ω–∞–ª–µ VS Code –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
    print("   python -m venv venv")
    print("   venv\\\\Scripts\\\\activate")
    print("   pip install -r requirements.txt")
    print("3. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω")
    print("4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python src/main.py")
    print("="*50)

if __name__ == "__main__":
    create_project_structure()